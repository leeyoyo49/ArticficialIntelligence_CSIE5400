{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "# import pytesseract  # uncomment if you need OCR\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig\n",
    "from PyPDF2 import PdfReader\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE = \"AI.pdf\"                 # Path to your PDF\n",
    "IMG_DIR = \"pdf_pages\"        # Where to save images\n",
    "OUTPUT_DIR = \"pdf_pages2\"        # Where to save images and JSON\n",
    "MODEL_ID = \"microsoft/Phi-4-multimodal-instruct\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI lecture slide analyzer. The following input is an image of a lecture slide about “Artificial Intelligence.”\n",
    "1. Extract every piece of written content: slide title, sub-bullets and their full text, definitions, formulas, and any inline examples.\n",
    "2. Generate a summary of at least 300 words, as thorough and precise as possible, for retrieval and generation.\n",
    "3. Select at least 5 of the most relevant keywords from the slide.\n",
    "4. If the slide shows a plot, include a description of the plot.\n",
    "5. If the slide contains a formula, save it in LaTeX format, and describe the formula as thorough as possible.\n",
    "\"\"\"\n",
    "\n",
    "# --- Model Setup ---\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_ID)\n",
    "generation_config.max_new_tokens = 1024\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    _attn_implementation=\"flash_attention_2\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "def caption_with_phi4(img: Image.Image, system: str) -> str:\n",
    "    prompt = (\n",
    "        \"<|im_start|>system<|im_sep|>\"\n",
    "        + system.strip()\n",
    "        + \"<|im_start|>user<|im_sep|>I'm a student learning artificial intelligence, teach me every thing in this slide.<|im_end|>\"\n",
    "        + \"<|image_1|><|im_end|>\"\n",
    "        + \"<|im_start|>assistant<|im_sep|>\"\n",
    "    )\n",
    "    inputs = processor(images=img, text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.2,     # 保持一致性\n",
    "            num_beams=2,          # 提高质量\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    return processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def extract_json(raw_caption: str) -> str:\n",
    "    # 1) Try regex for the assistant block\n",
    "    m = re.search(r\"<\\|im_start\\|>assistant<\\|im_sep\\|>(\\{[\\s\\S]*\\})\", raw_caption)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    # 2) Fallback: split on the last separator\n",
    "    parts = raw_caption.rsplit(\"<|im_start|>assistant<|im_sep|>\", 1)\n",
    "    return parts[-1].strip()\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "failed = []\n",
    "# --- Main Loop: process each page ---\n",
    "reader = PdfReader(FILE)\n",
    "\n",
    "for page_num in range(1, len(reader.pages) + 1):\n",
    "    # read img \n",
    "    img = Image.open(IMG_DIR + f\"/page_{page_num:03d}.png\")\n",
    "    base = f\"page_{page_num:03d}\"\n",
    "\n",
    "    # 2. Generate raw caption\n",
    "    raw_caption = caption_with_phi4(img, SYSTEM_PROMPT)\n",
    "    # save raw caption\n",
    "    with open(os.path.join(OUTPUT_DIR, base + \"_caption.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(raw_caption)\n",
    "\n",
    "    outputstr = extract_json(raw_caption)\n",
    "    print(f\"outputstr: {outputstr}\")\n",
    "    # 4. Parse (to verify) and save raw JSON text into .txt\n",
    "    try:\n",
    "        # save the raw JSON string into a .txt file\n",
    "        txt_path = os.path.join(OUTPUT_DIR, base + \"_caption_strip.txt\")\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(outputstr)\n",
    "\n",
    "        print(f\"✅  page_{page_num:03d} processed, saved to {txt_path}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ page_{page_num:03d} decode error: {e}\")\n",
    "        failed.append(page_num)\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del img\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "# save failed into txt\n",
    "with open(os.path.join(OUTPUT_DIR, \"failed.txt\"), \"w\") as f:\n",
    "    for page_num in failed:\n",
    "        f.write(f\"{page_num}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save into chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading page_001_caption_strip.txt\n",
      "loading page_002_caption_strip.txt\n",
      "loading page_003_caption_strip.txt\n",
      "loading page_004_caption_strip.txt\n",
      "loading page_005_caption_strip.txt\n",
      "loading page_006_caption_strip.txt\n",
      "loading page_007_caption_strip.txt\n",
      "loading page_008_caption_strip.txt\n",
      "loading page_009_caption_strip.txt\n",
      "loading page_010_caption_strip.txt\n",
      "loading page_011_caption_strip.txt\n",
      "loading page_012_caption_strip.txt\n",
      "loading page_013_caption_strip.txt\n",
      "loading page_014_caption_strip.txt\n",
      "loading page_015_caption_strip.txt\n",
      "loading page_016_caption_strip.txt\n",
      "loading page_017_caption_strip.txt\n",
      "loading page_018_caption_strip.txt\n",
      "loading page_019_caption_strip.txt\n",
      "loading page_020_caption_strip.txt\n",
      "loading page_021_caption_strip.txt\n",
      "loading page_022_caption_strip.txt\n",
      "loading page_023_caption_strip.txt\n",
      "loading page_024_caption_strip.txt\n",
      "loading page_025_caption_strip.txt\n",
      "loading page_026_caption_strip.txt\n",
      "loading page_027_caption_strip.txt\n",
      "loading page_028_caption_strip.txt\n",
      "loading page_029_caption_strip.txt\n",
      "loading page_030_caption_strip.txt\n",
      "loading page_031_caption_strip.txt\n",
      "loading page_032_caption_strip.txt\n",
      "loading page_033_caption_strip.txt\n",
      "loading page_034_caption_strip.txt\n",
      "loading page_035_caption_strip.txt\n",
      "loading page_036_caption_strip.txt\n",
      "loading page_037_caption_strip.txt\n",
      "loading page_038_caption_strip.txt\n",
      "loading page_039_caption_strip.txt\n",
      "loading page_040_caption_strip.txt\n",
      "loading page_041_caption_strip.txt\n",
      "loading page_042_caption_strip.txt\n",
      "loading page_043_caption_strip.txt\n",
      "loading page_044_caption_strip.txt\n",
      "loading page_045_caption_strip.txt\n",
      "loading page_046_caption_strip.txt\n",
      "loading page_047_caption_strip.txt\n",
      "loading page_048_caption_strip.txt\n",
      "loading page_049_caption_strip.txt\n",
      "loading page_050_caption_strip.txt\n",
      "loading page_051_caption_strip.txt\n",
      "loading page_052_caption_strip.txt\n",
      "loading page_053_caption_strip.txt\n",
      "loading page_054_caption_strip.txt\n",
      "loading page_055_caption_strip.txt\n",
      "loading page_056_caption_strip.txt\n",
      "loading page_057_caption_strip.txt\n",
      "loading page_058_caption_strip.txt\n",
      "loading page_059_caption_strip.txt\n",
      "loading page_060_caption_strip.txt\n",
      "loading page_061_caption_strip.txt\n",
      "loading page_062_caption_strip.txt\n",
      "loading page_063_caption_strip.txt\n",
      "loading page_064_caption_strip.txt\n",
      "loading page_065_caption_strip.txt\n",
      "loading page_066_caption_strip.txt\n",
      "loading page_067_caption_strip.txt\n",
      "loading page_068_caption_strip.txt\n",
      "loading page_069_caption_strip.txt\n",
      "loading page_070_caption_strip.txt\n",
      "loading page_071_caption_strip.txt\n",
      "loading page_072_caption_strip.txt\n",
      "loading page_073_caption_strip.txt\n",
      "loading page_074_caption_strip.txt\n",
      "loading page_075_caption_strip.txt\n",
      "loading page_076_caption_strip.txt\n",
      "loading page_077_caption_strip.txt\n",
      "loading page_078_caption_strip.txt\n",
      "loading page_079_caption_strip.txt\n",
      "loading page_080_caption_strip.txt\n",
      "loading page_081_caption_strip.txt\n",
      "loading page_082_caption_strip.txt\n",
      "loading page_083_caption_strip.txt\n",
      "loading page_084_caption_strip.txt\n",
      "loading page_085_caption_strip.txt\n",
      "loading page_086_caption_strip.txt\n",
      "loading page_087_caption_strip.txt\n",
      "loading page_088_caption_strip.txt\n",
      "loading page_089_caption_strip.txt\n",
      "loading page_090_caption_strip.txt\n",
      "loading page_091_caption_strip.txt\n",
      "loading page_092_caption_strip.txt\n",
      "loading page_093_caption_strip.txt\n",
      "loading page_094_caption_strip.txt\n",
      "loading page_095_caption_strip.txt\n",
      "loading page_096_caption_strip.txt\n",
      "loading page_097_caption_strip.txt\n",
      "loading page_098_caption_strip.txt\n",
      "loading page_099_caption_strip.txt\n",
      "loading page_100_caption_strip.txt\n",
      "loading page_101_caption_strip.txt\n",
      "loading page_102_caption_strip.txt\n",
      "loading page_103_caption_strip.txt\n",
      "loading page_104_caption_strip.txt\n",
      "loading page_105_caption_strip.txt\n",
      "loading page_106_caption_strip.txt\n",
      "loading page_107_caption_strip.txt\n",
      "loading page_108_caption_strip.txt\n",
      "loading page_109_caption_strip.txt\n",
      "loading page_110_caption_strip.txt\n",
      "loading page_111_caption_strip.txt\n",
      "loading page_112_caption_strip.txt\n",
      "loading page_113_caption_strip.txt\n",
      "loading page_114_caption_strip.txt\n",
      "loading page_115_caption_strip.txt\n",
      "loading page_116_caption_strip.txt\n",
      "loading page_117_caption_strip.txt\n",
      "loading page_118_caption_strip.txt\n",
      "loading page_119_caption_strip.txt\n",
      "loading page_120_caption_strip.txt\n",
      "loading page_121_caption_strip.txt\n",
      "loading page_122_caption_strip.txt\n",
      "loading page_123_caption_strip.txt\n",
      "loading page_124_caption_strip.txt\n",
      "loading page_125_caption_strip.txt\n",
      "loading page_126_caption_strip.txt\n",
      "loading page_127_caption_strip.txt\n",
      "loading page_128_caption_strip.txt\n",
      "loading page_129_caption_strip.txt\n",
      "loading page_130_caption_strip.txt\n",
      "loading page_131_caption_strip.txt\n",
      "loading page_132_caption_strip.txt\n",
      "loading page_133_caption_strip.txt\n",
      "loading page_134_caption_strip.txt\n",
      "loading page_135_caption_strip.txt\n",
      "loading page_136_caption_strip.txt\n",
      "loading page_137_caption_strip.txt\n",
      "loading page_138_caption_strip.txt\n",
      "loading page_139_caption_strip.txt\n",
      "loading page_140_caption_strip.txt\n",
      "loading page_141_caption_strip.txt\n",
      "loading page_142_caption_strip.txt\n",
      "loading page_143_caption_strip.txt\n",
      "loading page_144_caption_strip.txt\n",
      "loading page_145_caption_strip.txt\n",
      "loading page_146_caption_strip.txt\n",
      "loading page_147_caption_strip.txt\n",
      "loading page_148_caption_strip.txt\n",
      "loading page_149_caption_strip.txt\n",
      "loading page_150_caption_strip.txt\n",
      "loading page_151_caption_strip.txt\n",
      "loading page_152_caption_strip.txt\n",
      "loading page_153_caption_strip.txt\n",
      "loading page_154_caption_strip.txt\n",
      "loading page_155_caption_strip.txt\n",
      "loading page_156_caption_strip.txt\n",
      "loading page_157_caption_strip.txt\n",
      "loading page_158_caption_strip.txt\n",
      "loading page_159_caption_strip.txt\n",
      "loading page_160_caption_strip.txt\n",
      "loading page_161_caption_strip.txt\n",
      "loading page_162_caption_strip.txt\n",
      "loading page_163_caption_strip.txt\n",
      "loading page_164_caption_strip.txt\n",
      "loading page_165_caption_strip.txt\n",
      "loading page_166_caption_strip.txt\n",
      "loading page_167_caption_strip.txt\n",
      "loading page_168_caption_strip.txt\n",
      "loading page_169_caption_strip.txt\n",
      "loading page_170_caption_strip.txt\n",
      "loading page_171_caption_strip.txt\n",
      "loading page_172_caption_strip.txt\n",
      "loading page_173_caption_strip.txt\n",
      "loading page_174_caption_strip.txt\n",
      "loading page_175_caption_strip.txt\n",
      "loading page_176_caption_strip.txt\n",
      "loading page_177_caption_strip.txt\n",
      "loading page_178_caption_strip.txt\n",
      "loading page_179_caption_strip.txt\n",
      "loading page_180_caption_strip.txt\n",
      "loading page_181_caption_strip.txt\n",
      "loading page_182_caption_strip.txt\n",
      "loading page_183_caption_strip.txt\n",
      "loading page_184_caption_strip.txt\n",
      "loading page_185_caption_strip.txt\n",
      "loading page_186_caption_strip.txt\n",
      "loading page_187_caption_strip.txt\n",
      "loading page_188_caption_strip.txt\n",
      "loading page_189_caption_strip.txt\n",
      "loading page_190_caption_strip.txt\n",
      "loading page_191_caption_strip.txt\n",
      "loading page_192_caption_strip.txt\n",
      "loading page_193_caption_strip.txt\n",
      "loading page_194_caption_strip.txt\n",
      "loading page_195_caption_strip.txt\n",
      "loading page_196_caption_strip.txt\n",
      "loading page_197_caption_strip.txt\n",
      "loading page_198_caption_strip.txt\n",
      "loading page_199_caption_strip.txt\n",
      "loading page_200_caption_strip.txt\n",
      "loading page_201_caption_strip.txt\n",
      "loading page_202_caption_strip.txt\n",
      "loading page_203_caption_strip.txt\n",
      "loading page_204_caption_strip.txt\n",
      "loading page_205_caption_strip.txt\n",
      "loading page_206_caption_strip.txt\n",
      "loading page_207_caption_strip.txt\n",
      "loading page_208_caption_strip.txt\n",
      "loading page_209_caption_strip.txt\n",
      "loading page_210_caption_strip.txt\n",
      "loading page_211_caption_strip.txt\n",
      "loading page_212_caption_strip.txt\n",
      "loading page_213_caption_strip.txt\n",
      "loading page_214_caption_strip.txt\n",
      "loading page_215_caption_strip.txt\n",
      "loading page_216_caption_strip.txt\n",
      "loading page_217_caption_strip.txt\n",
      "loading page_218_caption_strip.txt\n",
      "loading page_219_caption_strip.txt\n",
      "loading page_220_caption_strip.txt\n",
      "loading page_221_caption_strip.txt\n",
      "loading page_222_caption_strip.txt\n",
      "loading page_223_caption_strip.txt\n",
      "loading page_224_caption_strip.txt\n",
      "loading page_225_caption_strip.txt\n",
      "loading page_226_caption_strip.txt\n",
      "loading page_227_caption_strip.txt\n",
      "loading page_228_caption_strip.txt\n",
      "loading page_229_caption_strip.txt\n",
      "loading page_230_caption_strip.txt\n",
      "loading page_231_caption_strip.txt\n",
      "loading page_232_caption_strip.txt\n",
      "loading page_233_caption_strip.txt\n",
      "loading page_234_caption_strip.txt\n",
      "loading page_235_caption_strip.txt\n",
      "loading page_236_caption_strip.txt\n",
      "loading page_237_caption_strip.txt\n",
      "loading page_238_caption_strip.txt\n",
      "loading page_239_caption_strip.txt\n",
      "loading page_240_caption_strip.txt\n",
      "loading page_241_caption_strip.txt\n",
      "loading page_242_caption_strip.txt\n",
      "loading page_243_caption_strip.txt\n",
      "loading page_244_caption_strip.txt\n",
      "loading page_245_caption_strip.txt\n",
      "loading page_246_caption_strip.txt\n",
      "loading page_247_caption_strip.txt\n",
      "loading page_248_caption_strip.txt\n",
      "loading page_249_caption_strip.txt\n",
      "loading page_250_caption_strip.txt\n",
      "loading page_251_caption_strip.txt\n",
      "loading page_252_caption_strip.txt\n",
      "loading page_253_caption_strip.txt\n",
      "loading page_254_caption_strip.txt\n",
      "loading page_255_caption_strip.txt\n",
      "loading page_256_caption_strip.txt\n",
      "loading page_257_caption_strip.txt\n",
      "loading page_258_caption_strip.txt\n",
      "loading page_259_caption_strip.txt\n",
      "loading page_260_caption_strip.txt\n",
      "loading page_261_caption_strip.txt\n",
      "loading page_262_caption_strip.txt\n",
      "loading page_263_caption_strip.txt\n",
      "loading page_264_caption_strip.txt\n",
      "loading page_265_caption_strip.txt\n",
      "loading page_266_caption_strip.txt\n",
      "loading page_267_caption_strip.txt\n",
      "loading page_268_caption_strip.txt\n",
      "loading page_269_caption_strip.txt\n",
      "loading page_270_caption_strip.txt\n",
      "loading page_271_caption_strip.txt\n",
      "loading page_272_caption_strip.txt\n",
      "loading page_273_caption_strip.txt\n",
      "loading page_274_caption_strip.txt\n",
      "loading page_275_caption_strip.txt\n",
      "loading page_276_caption_strip.txt\n",
      "loading page_277_caption_strip.txt\n",
      "loading page_278_caption_strip.txt\n",
      "loading page_279_caption_strip.txt\n",
      "loading page_280_caption_strip.txt\n",
      "loading page_281_caption_strip.txt\n",
      "loading page_282_caption_strip.txt\n",
      "loading page_283_caption_strip.txt\n",
      "loading page_284_caption_strip.txt\n",
      "loading page_285_caption_strip.txt\n",
      "loading page_286_caption_strip.txt\n",
      "loading page_287_caption_strip.txt\n",
      "loading page_288_caption_strip.txt\n",
      "loading page_289_caption_strip.txt\n",
      "loading page_290_caption_strip.txt\n",
      "loading page_291_caption_strip.txt\n",
      "loading page_292_caption_strip.txt\n",
      "loading page_293_caption_strip.txt\n",
      "loading page_294_caption_strip.txt\n",
      "loading page_295_caption_strip.txt\n",
      "loading page_296_caption_strip.txt\n",
      "loading page_297_caption_strip.txt\n",
      "loading page_298_caption_strip.txt\n",
      "loading page_299_caption_strip.txt\n",
      "loading page_300_caption_strip.txt\n",
      "loading page_301_caption_strip.txt\n",
      "loading page_302_caption_strip.txt\n",
      "loading page_303_caption_strip.txt\n",
      "loading page_304_caption_strip.txt\n",
      "loading page_305_caption_strip.txt\n",
      "loading page_306_caption_strip.txt\n",
      "loading page_307_caption_strip.txt\n",
      "loading page_308_caption_strip.txt\n",
      "loading page_309_caption_strip.txt\n",
      "loading page_310_caption_strip.txt\n",
      "loading page_311_caption_strip.txt\n",
      "loading page_312_caption_strip.txt\n",
      "loading page_313_caption_strip.txt\n",
      "loading page_314_caption_strip.txt\n",
      "loading page_315_caption_strip.txt\n",
      "loading page_316_caption_strip.txt\n",
      "loading page_317_caption_strip.txt\n",
      "loading page_318_caption_strip.txt\n",
      "loading page_319_caption_strip.txt\n",
      "loading page_320_caption_strip.txt\n",
      "loading page_321_caption_strip.txt\n",
      "loading page_322_caption_strip.txt\n",
      "loading page_323_caption_strip.txt\n",
      "loading page_324_caption_strip.txt\n",
      "loading page_325_caption_strip.txt\n",
      "loading page_326_caption_strip.txt\n",
      "loading page_327_caption_strip.txt\n",
      "loading page_328_caption_strip.txt\n",
      "loading page_329_caption_strip.txt\n",
      "loading page_330_caption_strip.txt\n",
      "loading page_331_caption_strip.txt\n",
      "loading page_332_caption_strip.txt\n",
      "loading page_333_caption_strip.txt\n",
      "loading page_334_caption_strip.txt\n",
      "loading page_335_caption_strip.txt\n",
      "loading page_336_caption_strip.txt\n",
      "loading page_337_caption_strip.txt\n",
      "loading page_338_caption_strip.txt\n",
      "loading page_339_caption_strip.txt\n",
      "loading page_340_caption_strip.txt\n",
      "loading page_341_caption_strip.txt\n",
      "loading page_342_caption_strip.txt\n",
      "loading page_343_caption_strip.txt\n",
      "loading page_344_caption_strip.txt\n",
      "loading page_345_caption_strip.txt\n",
      "loading page_346_caption_strip.txt\n",
      "loading page_347_caption_strip.txt\n",
      "loading page_348_caption_strip.txt\n",
      "loading page_349_caption_strip.txt\n",
      "loading page_350_caption_strip.txt\n",
      "loading page_351_caption_strip.txt\n",
      "loading page_352_caption_strip.txt\n",
      "loading page_353_caption_strip.txt\n",
      "loading page_354_caption_strip.txt\n",
      "loading page_355_caption_strip.txt\n",
      "loading page_356_caption_strip.txt\n",
      "loading page_357_caption_strip.txt\n",
      "loading page_358_caption_strip.txt\n",
      "loading page_359_caption_strip.txt\n",
      "loading page_360_caption_strip.txt\n",
      "loading page_361_caption_strip.txt\n",
      "loading page_362_caption_strip.txt\n",
      "loading page_363_caption_strip.txt\n",
      "loading page_364_caption_strip.txt\n",
      "loading page_365_caption_strip.txt\n",
      "loading page_366_caption_strip.txt\n",
      "loading page_367_caption_strip.txt\n",
      "loading page_368_caption_strip.txt\n",
      "loading page_369_caption_strip.txt\n",
      "loading page_370_caption_strip.txt\n",
      "loading page_371_caption_strip.txt\n",
      "loading page_372_caption_strip.txt\n",
      "loading page_373_caption_strip.txt\n",
      "loading page_374_caption_strip.txt\n",
      "loading page_375_caption_strip.txt\n",
      "loading page_376_caption_strip.txt\n",
      "loading page_377_caption_strip.txt\n",
      "loading page_378_caption_strip.txt\n",
      "loading page_379_caption_strip.txt\n",
      "loading page_380_caption_strip.txt\n",
      "loading page_381_caption_strip.txt\n",
      "loading page_382_caption_strip.txt\n",
      "loading page_383_caption_strip.txt\n",
      "loading page_384_caption_strip.txt\n",
      "loading page_385_caption_strip.txt\n",
      "loading page_386_caption_strip.txt\n",
      "loading page_387_caption_strip.txt\n",
      "loading page_388_caption_strip.txt\n",
      "loading page_389_caption_strip.txt\n",
      "loading page_390_caption_strip.txt\n",
      "loading page_391_caption_strip.txt\n",
      "loading page_392_caption_strip.txt\n",
      "loading page_393_caption_strip.txt\n",
      "loading page_394_caption_strip.txt\n",
      "loading page_395_caption_strip.txt\n",
      "loading page_396_caption_strip.txt\n",
      "loading page_397_caption_strip.txt\n",
      "loading page_398_caption_strip.txt\n",
      "loading page_399_caption_strip.txt\n",
      "loading page_400_caption_strip.txt\n",
      "loading page_401_caption_strip.txt\n",
      "loading page_402_caption_strip.txt\n",
      "loading page_403_caption_strip.txt\n",
      "loading page_404_caption_strip.txt\n",
      "loading page_405_caption_strip.txt\n",
      "loading page_406_caption_strip.txt\n",
      "loading page_407_caption_strip.txt\n",
      "loading page_408_caption_strip.txt\n",
      "loading page_409_caption_strip.txt\n",
      "loading page_410_caption_strip.txt\n",
      "loading page_411_caption_strip.txt\n",
      "loading page_412_caption_strip.txt\n",
      "loading page_413_caption_strip.txt\n",
      "loading page_414_caption_strip.txt\n",
      "loading page_415_caption_strip.txt\n",
      "loading page_416_caption_strip.txt\n",
      "loading page_417_caption_strip.txt\n",
      "loading page_418_caption_strip.txt\n",
      "loading page_419_caption_strip.txt\n",
      "loading page_420_caption_strip.txt\n",
      "loading page_421_caption_strip.txt\n",
      "loading page_422_caption_strip.txt\n",
      "loading page_423_caption_strip.txt\n",
      "loading page_424_caption_strip.txt\n",
      "loading page_425_caption_strip.txt\n",
      "loading page_426_caption_strip.txt\n",
      "loading page_427_caption_strip.txt\n",
      "loading page_428_caption_strip.txt\n",
      "loading page_429_caption_strip.txt\n",
      "loading page_430_caption_strip.txt\n",
      "loading page_431_caption_strip.txt\n",
      "loading page_432_caption_strip.txt\n",
      "loading page_433_caption_strip.txt\n",
      "loading page_434_caption_strip.txt\n",
      "loading page_435_caption_strip.txt\n",
      "loading page_436_caption_strip.txt\n",
      "loading page_437_caption_strip.txt\n",
      "loading page_438_caption_strip.txt\n",
      "loading page_439_caption_strip.txt\n",
      "loading page_440_caption_strip.txt\n",
      "loading page_441_caption_strip.txt\n",
      "loading page_442_caption_strip.txt\n",
      "loading page_443_caption_strip.txt\n",
      "loading page_444_caption_strip.txt\n",
      "loading page_445_caption_strip.txt\n",
      "loading page_446_caption_strip.txt\n",
      "loading page_447_caption_strip.txt\n",
      "loading page_448_caption_strip.txt\n",
      "loading page_449_caption_strip.txt\n",
      "loading page_450_caption_strip.txt\n",
      "loading page_451_caption_strip.txt\n",
      "loading page_452_caption_strip.txt\n",
      "loading page_453_caption_strip.txt\n",
      "loading page_454_caption_strip.txt\n",
      "loading page_455_caption_strip.txt\n",
      "loading page_456_caption_strip.txt\n",
      "loading page_457_caption_strip.txt\n",
      "loading page_458_caption_strip.txt\n",
      "loading page_459_caption_strip.txt\n",
      "loading page_460_caption_strip.txt\n",
      "loading page_461_caption_strip.txt\n",
      "loading page_462_caption_strip.txt\n",
      "loading page_463_caption_strip.txt\n",
      "Persisted 463 documents into ./chroma_db_task2-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295707/4063861571.py:39: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# File: build_chromadb.py\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_DIR = \"pdf_pages2\"\n",
    "DB_PATH = \"./chroma_db_task2-2\"\n",
    "EMBEDDINGS = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "\n",
    "docs = []\n",
    "for fname in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    if not fname.endswith(\"_caption_strip.txt\"):\n",
    "        continue\n",
    "    print(\"loading\", fname)\n",
    "    page = int(fname.split(\"_\")[1])\n",
    "    path = os.path.join(OUTPUT_DIR, fname)\n",
    "\n",
    "    # 讀入原始 JSON 字串\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # 組成要存入向量庫的純文字\n",
    "    text = f\"Page {page}\\Caption: {data}\"\n",
    "\n",
    "    docs.append(Document(page_content=data, metadata={\"page\": page}))\n",
    "\n",
    "# 建立並 persist Chroma 向量庫\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=DB_PATH\n",
    ")\n",
    "vectordb.persist()\n",
    "\n",
    "print(f\"Persisted {len(docs)} documents into {DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse through 103-174, remove everything\n",
    "for i in range(103, 175):\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"page_{i:03d}_caption_strip.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labstudent/miniconda3/envs/aicourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating queries split: 200 examples [00:00, 35874.82 examples/s]\n",
      "/tmp/ipykernel_309890/1123153093.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/tmp/ipykernel_309890/1123153093.py:11: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb   = Chroma(persist_directory=\"./chroma_db_task2-2\", embedding_function=embeddings)\n",
      "/home/labstudent/miniconda3/envs/aicourse/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "/home/labstudent/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/0af439b3adb8c23fda473c4f86001dbf9a226021/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:32<00:00, 10.67s/it]\n",
      "Device set to use cuda:0\n",
      "Parameter 'function'=<function add_context at 0x7689b02e5a20> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map:   0%|          | 0/200 [00:00<?, ? examples/s]/tmp/ipykernel_309890/1123153093.py:23: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(example[\"Question\"])\n",
      "Map: 100%|██████████| 200/200 [00:02<00:00, 77.27 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Load your CSV as a Dataset\n",
    "ds = load_dataset(\"csv\", data_files={\"queries\": \"queries.csv\"})[\"queries\"]\n",
    "\n",
    "# 2. Initialize your retriever (once, on CPU) and your HF pipeline (on GPU)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb   = Chroma(persist_directory=\"./chroma_db_task2-2\", embedding_function=embeddings)\n",
    "retriever  = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-4-multimodal-instruct\",\n",
    "                                          trust_remote_code=True, use_fast=True)\n",
    "model     = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-4-multimodal-instruct\",\n",
    "                                                 trust_remote_code=True).to(\"cuda\")\n",
    "hf_pipe   = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,\n",
    "                     trust_remote_code=True, device=0, return_full_text=False)\n",
    "\n",
    "# 3. Precompute your contexts (summaries) column\n",
    "def add_context(example):\n",
    "    docs = retriever.get_relevant_documents(example[\"Question\"])\n",
    "    example[\"context\"] = \"\\n\".join(d.page_content for d in docs)\n",
    "    return example\n",
    "\n",
    "ds = ds.map(add_context)\n",
    "\n",
    "# 4. Define your batched generation function\n",
    "prompt_tmpl = \"\"\"\\\n",
    "You have extracts from multiple pages, each prefixed with \"Page <number>:\".  \n",
    "Use all of them to answer the user's question, but output only the integer page number  \n",
    "of the page that best answers the question. No extra text.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "def generate_batch(batch):\n",
    "    prompts = [\n",
    "        prompt_tmpl.format(context=c, question=q)\n",
    "        for c, q in zip(batch[\"context\"], batch[\"Question\"])\n",
    "    ]\n",
    "    outputs = hf_pipe(prompts, batch_size=8, max_new_tokens=32)\n",
    "    batch[\"Answer\"] = [out[\"generated_text\"].strip() for out in outputs]\n",
    "    return batch\n",
    "\n",
    "# 5. Run it all in one go, on GPU\n",
    "ds = ds.map(generate_batch, batched=True, batch_size=8)\n",
    "\n",
    "# 6. Save\n",
    "ds.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
