{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "# import pytesseract  # uncomment if you need OCR\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig\n",
    "from PyPDF2 import PdfReader\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE = \"AI.pdf\"                 # Path to your PDF\n",
    "OUTPUT_DIR = \"pdf_pages\"        # Where to save images and JSON\n",
    "MODEL_ID = \"microsoft/Phi-4-multimodal-instruct\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI lecture slide analyzer. The following input is an image and the OCR of a lecture slide about “Artificial Intelligence.”\n",
    "1. Extract every piece of written content: slide title, sub-bullets and their full text, definitions, formulas, and any inline examples.\n",
    "2. Generate a summary of at least 300 words, as thorough and precise as possible, for retrieval and generation.\n",
    "3. Select at least 5 of the most relevant keywords from the slide.\n",
    "4. If the slide shows a plot, include a description of the plot.\n",
    "5. Organize your output as a valid JSON object with these fields:\n",
    "   {\n",
    "     \"title\": string,\n",
    "     \"summary\": string,\n",
    "     \"definitions\": { term: definition },\n",
    "     \"keywords\": [ string ],\n",
    "     \"formulas\": [ string ]\n",
    "   }\n",
    "6. Output ONLY the JSON object as a string, with no extra text or formatting.\n",
    "\"\"\"\n",
    "\n",
    "# --- Model Setup ---\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_ID)\n",
    "generation_config.max_new_tokens = 1024\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    _attn_implementation=\"flash_attention_2\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "def caption_with_phi4(img: Image.Image, system: str) -> str:\n",
    "    prompt = (\n",
    "        \"<|im_start|>system<|im_sep|>\"\n",
    "        + system.strip()\n",
    "        + \"<|image_1|><|im_end|>\"\n",
    "        + \"<|im_start|>assistant<|im_sep|>\"\n",
    "    )\n",
    "    inputs = processor(images=img, text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=1024,\n",
    "            temperature=0.0,     # 保持一致性\n",
    "            num_beams=5,          # 提高质量\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    return processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "failed = []\n",
    "# --- Main Loop: process each page ---\n",
    "reader = PdfReader(FILE)\n",
    "for page_num in range(1, len(reader.pages) + 1):\n",
    "\n",
    "    # read img \n",
    "    img = Image.open(OUTPUT_DIR + f\"/page_{page_num:03d}.png\")\n",
    "    base = f\"page_{page_num:03d}\"\n",
    "\n",
    "    # 2. Generate raw caption\n",
    "    raw_caption = caption_with_phi4(img, SYSTEM_PROMPT)\n",
    "    # save raw caption\n",
    "    with open(os.path.join(OUTPUT_DIR, base + \"_caption.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(raw_caption)\n",
    "\n",
    "    # 3. Extract JSON payload\n",
    "    #   a) Try to capture fenced ```json ... ``` block\n",
    "    m = re.search(r\"```json\\s*(\\{[\\s\\S]*?\\})\\s*```\", raw_caption)\n",
    "    if m:\n",
    "        json_str = m.group(1)\n",
    "    else:\n",
    "        # b) Fallback: grab from first '{' to last '}'\n",
    "        start = raw_caption.find('{')\n",
    "        end   = raw_caption.rfind('}') + 1\n",
    "        if start != -1 and end != -1:\n",
    "            json_str = raw_caption[start:end]\n",
    "        else:\n",
    "            print(f\"❌ page_{page_num:03d}: could not locate JSON block\")\n",
    "            continue\n",
    "\n",
    "    # 4. Parse and save\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # save stripped JSON\n",
    "        with open(os.path.join(OUTPUT_DIR, base + \"_caption_strip.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # save page image\n",
    "        img.save(os.path.join(OUTPUT_DIR, base + \".png\"))\n",
    "        print(f\"✅  page_{page_num:03d} processed\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ page_{page_num:03d} JSON decode error: {e}\")\n",
    "        failed.append(page_num)\n",
    "        # optionally bump generation_config.max_new_tokens and retry here\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del img\n",
    "        gc.collect()\n",
    "\n",
    "# save failed into txt\n",
    "with open(os.path.join(OUTPUT_DIR, \"failed.txt\"), \"w\") as f:\n",
    "    for page_num in failed:\n",
    "        f.write(f\"{page_num}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save into chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading page_001_caption_strip.json\n",
      "loading page_002_caption_strip.json\n",
      "loading page_003_caption_strip.json\n",
      "loading page_004_caption_strip.json\n",
      "loading page_005_caption_strip.json\n",
      "loading page_006_caption_strip.json\n",
      "loading page_007_caption_strip.json\n",
      "loading page_008_caption_strip.json\n",
      "loading page_009_caption_strip.json\n",
      "loading page_010_caption_strip.json\n",
      "loading page_011_caption_strip.json\n",
      "loading page_012_caption_strip.json\n",
      "loading page_013_caption_strip.json\n",
      "loading page_014_caption_strip.json\n",
      "loading page_015_caption_strip.json\n",
      "loading page_016_caption_strip.json\n",
      "loading page_017_caption_strip.json\n",
      "loading page_018_caption_strip.json\n",
      "loading page_019_caption_strip.json\n",
      "loading page_020_caption_strip.json\n",
      "loading page_021_caption_strip.json\n",
      "loading page_022_caption_strip.json\n",
      "loading page_023_caption_strip.json\n",
      "loading page_024_caption_strip.json\n",
      "loading page_025_caption_strip.json\n",
      "loading page_026_caption_strip.json\n",
      "loading page_027_caption_strip.json\n",
      "loading page_028_caption_strip.json\n",
      "loading page_029_caption_strip.json\n",
      "loading page_030_caption_strip.json\n",
      "loading page_031_caption_strip.json\n",
      "loading page_032_caption_strip.json\n",
      "loading page_033_caption_strip.json\n",
      "loading page_034_caption_strip.json\n",
      "loading page_035_caption_strip.json\n",
      "loading page_036_caption_strip.json\n",
      "loading page_037_caption_strip.json\n",
      "loading page_038_caption_strip.json\n",
      "loading page_039_caption_strip.json\n",
      "loading page_040_caption_strip.json\n",
      "loading page_041_caption_strip.json\n",
      "loading page_042_caption_strip.json\n",
      "loading page_043_caption_strip.json\n",
      "loading page_044_caption_strip.json\n",
      "loading page_045_caption_strip.json\n",
      "loading page_046_caption_strip.json\n",
      "loading page_047_caption_strip.json\n",
      "loading page_048_caption_strip.json\n",
      "loading page_049_caption_strip.json\n",
      "loading page_050_caption_strip.json\n",
      "loading page_051_caption_strip.json\n",
      "loading page_052_caption_strip.json\n",
      "loading page_053_caption_strip.json\n",
      "loading page_054_caption_strip.json\n",
      "loading page_055_caption_strip.json\n",
      "loading page_056_caption_strip.json\n",
      "loading page_057_caption_strip.json\n",
      "loading page_058_caption_strip.json\n",
      "loading page_059_caption_strip.json\n",
      "loading page_060_caption_strip.json\n",
      "loading page_061_caption_strip.json\n",
      "loading page_062_caption_strip.json\n",
      "loading page_063_caption_strip.json\n",
      "loading page_064_caption_strip.json\n",
      "loading page_065_caption_strip.json\n",
      "loading page_066_caption_strip.json\n",
      "loading page_067_caption_strip.json\n",
      "loading page_068_caption_strip.json\n",
      "loading page_069_caption_strip.json\n",
      "loading page_070_caption_strip.json\n",
      "loading page_071_caption_strip.json\n",
      "loading page_072_caption_strip.json\n",
      "loading page_073_caption_strip.json\n",
      "loading page_074_caption_strip.json\n",
      "loading page_075_caption_strip.json\n",
      "loading page_076_caption_strip.json\n",
      "loading page_077_caption_strip.json\n",
      "loading page_078_caption_strip.json\n",
      "loading page_079_caption_strip.json\n",
      "loading page_080_caption_strip.json\n",
      "loading page_081_caption_strip.json\n",
      "loading page_082_caption_strip.json\n",
      "loading page_083_caption_strip.json\n",
      "loading page_084_caption_strip.json\n",
      "loading page_085_caption_strip.json\n",
      "loading page_086_caption_strip.json\n",
      "loading page_087_caption_strip.json\n",
      "loading page_088_caption_strip.json\n",
      "loading page_089_caption_strip.json\n",
      "loading page_090_caption_strip.json\n",
      "loading page_091_caption_strip.json\n",
      "loading page_092_caption_strip.json\n",
      "loading page_093_caption_strip.json\n",
      "loading page_094_caption_strip.json\n",
      "loading page_095_caption_strip.json\n",
      "loading page_096_caption_strip.json\n",
      "loading page_097_caption_strip.json\n",
      "loading page_098_caption_strip.json\n",
      "loading page_099_caption_strip.json\n",
      "loading page_100_caption_strip.json\n",
      "loading page_101_caption_strip.json\n",
      "loading page_102_caption_strip.json\n",
      "loading page_103_caption_strip.json\n",
      "loading page_104_caption_strip.json\n",
      "loading page_105_caption_strip.json\n",
      "loading page_106_caption_strip.json\n",
      "loading page_107_caption_strip.json\n",
      "loading page_108_caption_strip.json\n",
      "loading page_109_caption_strip.json\n",
      "loading page_110_caption_strip.json\n",
      "loading page_111_caption_strip.json\n",
      "loading page_112_caption_strip.json\n",
      "loading page_113_caption_strip.json\n",
      "loading page_114_caption_strip.json\n",
      "loading page_115_caption_strip.json\n",
      "loading page_116_caption_strip.json\n",
      "loading page_117_caption_strip.json\n",
      "loading page_118_caption_strip.json\n",
      "loading page_119_caption_strip.json\n",
      "loading page_120_caption_strip.json\n",
      "loading page_121_caption_strip.json\n",
      "loading page_122_caption_strip.json\n",
      "loading page_123_caption_strip.json\n",
      "loading page_124_caption_strip.json\n",
      "loading page_125_caption_strip.json\n",
      "loading page_126_caption_strip.json\n",
      "loading page_127_caption_strip.json\n",
      "loading page_128_caption_strip.json\n",
      "loading page_129_caption_strip.json\n",
      "loading page_130_caption_strip.json\n",
      "loading page_131_caption_strip.json\n",
      "loading page_132_caption_strip.json\n",
      "loading page_133_caption_strip.json\n",
      "loading page_134_caption_strip.json\n",
      "loading page_135_caption_strip.json\n",
      "loading page_136_caption_strip.json\n",
      "loading page_137_caption_strip.json\n",
      "loading page_138_caption_strip.json\n",
      "loading page_139_caption_strip.json\n",
      "loading page_140_caption_strip.json\n",
      "loading page_141_caption_strip.json\n",
      "loading page_142_caption_strip.json\n",
      "loading page_143_caption_strip.json\n",
      "loading page_144_caption_strip.json\n",
      "loading page_145_caption_strip.json\n",
      "loading page_146_caption_strip.json\n",
      "loading page_147_caption_strip.json\n",
      "loading page_148_caption_strip.json\n",
      "loading page_149_caption_strip.json\n",
      "loading page_150_caption_strip.json\n",
      "loading page_151_caption_strip.json\n",
      "loading page_152_caption_strip.json\n",
      "loading page_153_caption_strip.json\n",
      "loading page_154_caption_strip.json\n",
      "loading page_155_caption_strip.json\n",
      "loading page_156_caption_strip.json\n",
      "loading page_157_caption_strip.json\n",
      "loading page_158_caption_strip.json\n",
      "loading page_159_caption_strip.json\n",
      "loading page_160_caption_strip.json\n",
      "loading page_161_caption_strip.json\n",
      "loading page_162_caption_strip.json\n",
      "loading page_163_caption_strip.json\n",
      "loading page_164_caption_strip.json\n",
      "loading page_165_caption_strip.json\n",
      "loading page_166_caption_strip.json\n",
      "loading page_167_caption_strip.json\n",
      "loading page_168_caption_strip.json\n",
      "loading page_169_caption_strip.json\n",
      "loading page_170_caption_strip.json\n",
      "loading page_171_caption_strip.json\n",
      "loading page_172_caption_strip.json\n",
      "loading page_173_caption_strip.json\n",
      "loading page_174_caption_strip.json\n",
      "loading page_175_caption_strip.json\n",
      "loading page_176_caption_strip.json\n",
      "loading page_177_caption_strip.json\n",
      "loading page_178_caption_strip.json\n",
      "loading page_179_caption_strip.json\n",
      "loading page_180_caption_strip.json\n",
      "loading page_181_caption_strip.json\n",
      "loading page_182_caption_strip.json\n",
      "loading page_183_caption_strip.json\n",
      "loading page_184_caption_strip.json\n",
      "loading page_185_caption_strip.json\n",
      "loading page_186_caption_strip.json\n",
      "loading page_187_caption_strip.json\n",
      "loading page_188_caption_strip.json\n",
      "loading page_189_caption_strip.json\n",
      "loading page_190_caption_strip.json\n",
      "loading page_191_caption_strip.json\n",
      "loading page_192_caption_strip.json\n",
      "loading page_193_caption_strip.json\n",
      "loading page_194_caption_strip.json\n",
      "loading page_195_caption_strip.json\n",
      "loading page_196_caption_strip.json\n",
      "loading page_197_caption_strip.json\n",
      "loading page_198_caption_strip.json\n",
      "loading page_199_caption_strip.json\n",
      "loading page_200_caption_strip.json\n",
      "loading page_201_caption_strip.json\n",
      "loading page_202_caption_strip.json\n",
      "loading page_203_caption_strip.json\n",
      "loading page_204_caption_strip.json\n",
      "loading page_205_caption_strip.json\n",
      "loading page_206_caption_strip.json\n",
      "loading page_207_caption_strip.json\n",
      "loading page_208_caption_strip.json\n",
      "loading page_209_caption_strip.json\n",
      "loading page_210_caption_strip.json\n",
      "loading page_211_caption_strip.json\n",
      "loading page_212_caption_strip.json\n",
      "loading page_213_caption_strip.json\n",
      "loading page_214_caption_strip.json\n",
      "loading page_215_caption_strip.json\n",
      "loading page_216_caption_strip.json\n",
      "loading page_217_caption_strip.json\n",
      "loading page_218_caption_strip.json\n",
      "loading page_219_caption_strip.json\n",
      "loading page_220_caption_strip.json\n",
      "loading page_221_caption_strip.json\n",
      "loading page_222_caption_strip.json\n",
      "loading page_223_caption_strip.json\n",
      "loading page_224_caption_strip.json\n",
      "loading page_225_caption_strip.json\n",
      "loading page_226_caption_strip.json\n",
      "loading page_227_caption_strip.json\n",
      "loading page_228_caption_strip.json\n",
      "loading page_229_caption_strip.json\n",
      "loading page_230_caption_strip.json\n",
      "loading page_231_caption_strip.json\n",
      "loading page_232_caption_strip.json\n",
      "loading page_233_caption_strip.json\n",
      "loading page_234_caption_strip.json\n",
      "loading page_235_caption_strip.json\n",
      "loading page_236_caption_strip.json\n",
      "loading page_237_caption_strip.json\n",
      "loading page_238_caption_strip.json\n",
      "loading page_239_caption_strip.json\n",
      "loading page_240_caption_strip.json\n",
      "loading page_241_caption_strip.json\n",
      "loading page_242_caption_strip.json\n",
      "loading page_243_caption_strip.json\n",
      "loading page_244_caption_strip.json\n",
      "loading page_245_caption_strip.json\n",
      "loading page_246_caption_strip.json\n",
      "loading page_247_caption_strip.json\n",
      "loading page_248_caption_strip.json\n",
      "loading page_249_caption_strip.json\n",
      "loading page_250_caption_strip.json\n",
      "loading page_251_caption_strip.json\n",
      "loading page_252_caption_strip.json\n",
      "loading page_253_caption_strip.json\n",
      "loading page_254_caption_strip.json\n",
      "loading page_255_caption_strip.json\n",
      "loading page_256_caption_strip.json\n",
      "loading page_257_caption_strip.json\n",
      "loading page_258_caption_strip.json\n",
      "loading page_259_caption_strip.json\n",
      "loading page_260_caption_strip.json\n",
      "loading page_261_caption_strip.json\n",
      "loading page_262_caption_strip.json\n",
      "loading page_263_caption_strip.json\n",
      "loading page_264_caption_strip.json\n",
      "loading page_265_caption_strip.json\n",
      "loading page_266_caption_strip.json\n",
      "loading page_267_caption_strip.json\n",
      "loading page_268_caption_strip.json\n",
      "loading page_269_caption_strip.json\n",
      "loading page_270_caption_strip.json\n",
      "loading page_271_caption_strip.json\n",
      "loading page_272_caption_strip.json\n",
      "loading page_273_caption_strip.json\n",
      "loading page_274_caption_strip.json\n",
      "loading page_275_caption_strip.json\n",
      "loading page_276_caption_strip.json\n",
      "loading page_277_caption_strip.json\n",
      "loading page_278_caption_strip.json\n",
      "loading page_279_caption_strip.json\n",
      "loading page_280_caption_strip.json\n",
      "loading page_281_caption_strip.json\n",
      "loading page_282_caption_strip.json\n",
      "loading page_283_caption_strip.json\n",
      "loading page_284_caption_strip.json\n",
      "loading page_285_caption_strip.json\n",
      "loading page_286_caption_strip.json\n",
      "loading page_287_caption_strip.json\n",
      "loading page_288_caption_strip.json\n",
      "loading page_289_caption_strip.json\n",
      "loading page_290_caption_strip.json\n",
      "loading page_291_caption_strip.json\n",
      "loading page_292_caption_strip.json\n",
      "loading page_293_caption_strip.json\n",
      "loading page_294_caption_strip.json\n",
      "loading page_295_caption_strip.json\n",
      "loading page_296_caption_strip.json\n",
      "loading page_297_caption_strip.json\n",
      "loading page_298_caption_strip.json\n",
      "loading page_299_caption_strip.json\n",
      "loading page_300_caption_strip.json\n",
      "loading page_301_caption_strip.json\n",
      "loading page_302_caption_strip.json\n",
      "loading page_303_caption_strip.json\n",
      "loading page_304_caption_strip.json\n",
      "loading page_305_caption_strip.json\n",
      "loading page_306_caption_strip.json\n",
      "loading page_307_caption_strip.json\n",
      "loading page_308_caption_strip.json\n",
      "loading page_309_caption_strip.json\n",
      "loading page_310_caption_strip.json\n",
      "loading page_311_caption_strip.json\n",
      "loading page_312_caption_strip.json\n",
      "loading page_313_caption_strip.json\n",
      "loading page_314_caption_strip.json\n",
      "loading page_315_caption_strip.json\n",
      "loading page_316_caption_strip.json\n",
      "loading page_317_caption_strip.json\n",
      "loading page_318_caption_strip.json\n",
      "loading page_319_caption_strip.json\n",
      "loading page_320_caption_strip.json\n",
      "loading page_321_caption_strip.json\n",
      "loading page_322_caption_strip.json\n",
      "loading page_323_caption_strip.json\n",
      "loading page_324_caption_strip.json\n",
      "loading page_325_caption_strip.json\n",
      "loading page_326_caption_strip.json\n",
      "loading page_327_caption_strip.json\n",
      "loading page_328_caption_strip.json\n",
      "loading page_329_caption_strip.json\n",
      "loading page_330_caption_strip.json\n",
      "loading page_331_caption_strip.json\n",
      "loading page_332_caption_strip.json\n",
      "loading page_333_caption_strip.json\n",
      "loading page_334_caption_strip.json\n",
      "loading page_335_caption_strip.json\n",
      "loading page_336_caption_strip.json\n",
      "loading page_337_caption_strip.json\n",
      "loading page_338_caption_strip.json\n",
      "loading page_339_caption_strip.json\n",
      "loading page_340_caption_strip.json\n",
      "loading page_341_caption_strip.json\n",
      "loading page_342_caption_strip.json\n",
      "loading page_343_caption_strip.json\n",
      "loading page_344_caption_strip.json\n",
      "loading page_345_caption_strip.json\n",
      "loading page_346_caption_strip.json\n",
      "loading page_347_caption_strip.json\n",
      "loading page_348_caption_strip.json\n",
      "loading page_349_caption_strip.json\n",
      "loading page_350_caption_strip.json\n",
      "loading page_351_caption_strip.json\n",
      "loading page_352_caption_strip.json\n",
      "loading page_353_caption_strip.json\n",
      "loading page_354_caption_strip.json\n",
      "loading page_355_caption_strip.json\n",
      "loading page_356_caption_strip.json\n",
      "loading page_357_caption_strip.json\n",
      "loading page_358_caption_strip.json\n",
      "loading page_359_caption_strip.json\n",
      "loading page_360_caption_strip.json\n",
      "loading page_361_caption_strip.json\n",
      "loading page_362_caption_strip.json\n",
      "loading page_363_caption_strip.json\n",
      "loading page_364_caption_strip.json\n",
      "loading page_365_caption_strip.json\n",
      "loading page_366_caption_strip.json\n",
      "loading page_367_caption_strip.json\n",
      "loading page_368_caption_strip.json\n",
      "loading page_369_caption_strip.json\n",
      "loading page_370_caption_strip.json\n",
      "loading page_371_caption_strip.json\n",
      "loading page_372_caption_strip.json\n",
      "loading page_373_caption_strip.json\n",
      "loading page_374_caption_strip.json\n",
      "loading page_375_caption_strip.json\n",
      "loading page_376_caption_strip.json\n",
      "loading page_377_caption_strip.json\n",
      "loading page_378_caption_strip.json\n",
      "loading page_379_caption_strip.json\n",
      "loading page_380_caption_strip.json\n",
      "loading page_381_caption_strip.json\n",
      "loading page_382_caption_strip.json\n",
      "loading page_383_caption_strip.json\n",
      "loading page_384_caption_strip.json\n",
      "loading page_385_caption_strip.json\n",
      "loading page_386_caption_strip.json\n",
      "loading page_387_caption_strip.json\n",
      "loading page_388_caption_strip.json\n",
      "loading page_389_caption_strip.json\n",
      "loading page_390_caption_strip.json\n",
      "loading page_391_caption_strip.json\n",
      "loading page_392_caption_strip.json\n",
      "loading page_393_caption_strip.json\n",
      "loading page_394_caption_strip.json\n",
      "loading page_395_caption_strip.json\n",
      "loading page_396_caption_strip.json\n",
      "loading page_397_caption_strip.json\n",
      "loading page_398_caption_strip.json\n",
      "loading page_399_caption_strip.json\n",
      "loading page_400_caption_strip.json\n",
      "loading page_401_caption_strip.json\n",
      "loading page_402_caption_strip.json\n",
      "loading page_403_caption_strip.json\n",
      "loading page_404_caption_strip.json\n",
      "loading page_405_caption_strip.json\n",
      "loading page_406_caption_strip.json\n",
      "loading page_407_caption_strip.json\n",
      "loading page_408_caption_strip.json\n",
      "loading page_409_caption_strip.json\n",
      "loading page_410_caption_strip.json\n",
      "loading page_411_caption_strip.json\n",
      "loading page_412_caption_strip.json\n",
      "loading page_413_caption_strip.json\n",
      "loading page_414_caption_strip.json\n",
      "loading page_415_caption_strip.json\n",
      "loading page_416_caption_strip.json\n",
      "loading page_417_caption_strip.json\n",
      "loading page_418_caption_strip.json\n",
      "loading page_419_caption_strip.json\n",
      "loading page_421_caption_strip.json\n",
      "loading page_422_caption_strip.json\n",
      "loading page_423_caption_strip.json\n",
      "loading page_424_caption_strip.json\n",
      "loading page_425_caption_strip.json\n",
      "loading page_426_caption_strip.json\n",
      "loading page_427_caption_strip.json\n",
      "loading page_428_caption_strip.json\n",
      "loading page_429_caption_strip.json\n",
      "loading page_430_caption_strip.json\n",
      "loading page_431_caption_strip.json\n",
      "loading page_432_caption_strip.json\n",
      "loading page_433_caption_strip.json\n",
      "loading page_434_caption_strip.json\n",
      "loading page_435_caption_strip.json\n",
      "loading page_436_caption_strip.json\n",
      "loading page_437_caption_strip.json\n",
      "loading page_438_caption_strip.json\n",
      "loading page_439_caption_strip.json\n",
      "loading page_440_caption_strip.json\n",
      "loading page_441_caption_strip.json\n",
      "loading page_442_caption_strip.json\n",
      "loading page_443_caption_strip.json\n",
      "loading page_444_caption_strip.json\n",
      "loading page_445_caption_strip.json\n",
      "loading page_446_caption_strip.json\n",
      "loading page_447_caption_strip.json\n",
      "loading page_448_caption_strip.json\n",
      "loading page_449_caption_strip.json\n",
      "loading page_450_caption_strip.json\n",
      "loading page_451_caption_strip.json\n",
      "loading page_452_caption_strip.json\n",
      "loading page_453_caption_strip.json\n",
      "loading page_454_caption_strip.json\n",
      "loading page_455_caption_strip.json\n",
      "loading page_456_caption_strip.json\n",
      "loading page_457_caption_strip.json\n",
      "loading page_458_caption_strip.json\n",
      "loading page_459_caption_strip.json\n",
      "loading page_460_caption_strip.json\n",
      "loading page_461_caption_strip.json\n",
      "loading page_462_caption_strip.json\n",
      "loading page_463_caption_strip.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200333/3653513522.py:39: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
      "/home/labstudent/miniconda3/envs/aicourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted 462 documents into ./chroma_db_task2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200333/3653513522.py:46: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# File: build_chromadb.py\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "# 把下面這行由 langchain_chroma 改成官方的 langchain.vectorstores\n",
    "from langchain.vectorstores import Chroma\n",
    "# Embeddings 也改成官方路徑\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_DIR = \"pdf_pages\"\n",
    "DB_PATH = \"./chroma_db_task2\"\n",
    "EMBEDDINGS = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "def sanitize_json(raw: str) -> str:\n",
    "    # 先修正所有不合法的 \\uXXXX，再把其它非法反斜線全逃逸\n",
    "    raw = re.sub(r'\\\\u(?![0-9A-Fa-f]{4})', r'\\\\\\\\u', raw)\n",
    "    raw = re.sub(r'\\\\(?![\"\\\\/bfnrtu])',      r'\\\\\\\\', raw)\n",
    "    return raw\n",
    "\n",
    "docs = []\n",
    "for fname in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    if not fname.endswith(\"_caption_strip.json\"):\n",
    "        continue\n",
    "    print(\"loading\", fname)\n",
    "    page = int(fname.split(\"_\")[1])\n",
    "    path = os.path.join(OUTPUT_DIR, fname)\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    safe = sanitize_json(raw)\n",
    "    data = json.loads(safe)\n",
    "\n",
    "    text = f\"Page {page}\\nTitle: {data.get('title','')}\\n\\nSummary:\\n{data.get('summary','')}\"\n",
    "    docs.append(Document(page_content=text, metadata={\"page\": page}))\n",
    "\n",
    "# 這裡改成官方 Chroma.from_documents\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=DB_PATH\n",
    ")\n",
    "# 呼叫官方的 persist() 方法\n",
    "vectordb.persist()\n",
    "\n",
    "print(f\"Persisted {len(docs)} documents into {DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labstudent/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/0af439b3adb8c23fda473c4f86001dbf9a226021/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "Processing 20\n",
      "Processing 21\n",
      "Processing 22\n",
      "Processing 23\n",
      "Processing 24\n",
      "Processing 25\n",
      "Processing 26\n",
      "Processing 27\n",
      "Processing 28\n",
      "Processing 29\n",
      "Processing 30\n",
      "Processing 31\n",
      "Processing 32\n",
      "Processing 33\n",
      "Processing 34\n",
      "Processing 35\n",
      "Processing 36\n",
      "Processing 37\n",
      "Processing 38\n",
      "Processing 39\n",
      "Processing 40\n",
      "Processing 41\n",
      "Processing 42\n",
      "Processing 43\n",
      "Processing 44\n",
      "Processing 45\n",
      "Processing 46\n",
      "Processing 47\n",
      "Processing 48\n",
      "Processing 49\n",
      "Processing 50\n",
      "Processing 51\n",
      "Processing 52\n",
      "Processing 53\n",
      "Processing 54\n",
      "Processing 55\n",
      "Processing 56\n",
      "Processing 57\n",
      "Processing 58\n",
      "Processing 59\n",
      "Processing 60\n",
      "Processing 61\n",
      "Processing 62\n",
      "Processing 63\n",
      "Processing 64\n",
      "Processing 65\n",
      "Processing 66\n",
      "Processing 67\n",
      "Processing 68\n",
      "Processing 69\n",
      "Processing 70\n",
      "Processing 71\n",
      "Processing 72\n",
      "Processing 73\n",
      "Processing 74\n",
      "Processing 75\n",
      "Processing 76\n",
      "Processing 77\n",
      "Processing 78\n",
      "Processing 79\n",
      "Processing 80\n",
      "Processing 81\n",
      "Processing 82\n",
      "Processing 83\n",
      "Processing 84\n",
      "Processing 85\n",
      "Processing 86\n",
      "Processing 87\n",
      "Processing 88\n",
      "Processing 89\n",
      "Processing 90\n",
      "Processing 91\n",
      "Processing 92\n",
      "Processing 93\n",
      "Processing 94\n",
      "Processing 95\n",
      "Processing 96\n",
      "Processing 97\n",
      "Processing 98\n",
      "Processing 99\n",
      "Processing 100\n",
      "Processing 101\n",
      "Processing 102\n",
      "Processing 103\n",
      "Processing 104\n",
      "Processing 105\n",
      "Processing 106\n",
      "Processing 107\n",
      "Processing 108\n",
      "Processing 109\n",
      "Processing 110\n",
      "Processing 111\n",
      "Processing 112\n",
      "Processing 113\n",
      "Processing 114\n",
      "Processing 115\n",
      "Processing 116\n",
      "Processing 117\n",
      "Processing 118\n",
      "Processing 119\n",
      "Processing 120\n",
      "Processing 121\n",
      "Processing 122\n",
      "Processing 123\n",
      "Processing 124\n",
      "Processing 125\n",
      "Processing 126\n",
      "Processing 127\n",
      "Processing 128\n",
      "Processing 129\n",
      "Processing 130\n",
      "Processing 131\n",
      "Processing 132\n",
      "Processing 133\n",
      "Processing 134\n",
      "Processing 135\n",
      "Processing 136\n",
      "Processing 137\n",
      "Processing 138\n",
      "Processing 139\n",
      "Processing 140\n",
      "Processing 141\n",
      "Processing 142\n",
      "Processing 143\n",
      "Processing 144\n",
      "Processing 145\n",
      "Processing 146\n",
      "Processing 147\n",
      "Processing 148\n",
      "Processing 149\n",
      "Processing 150\n",
      "Processing 151\n",
      "Processing 152\n",
      "Processing 153\n",
      "Processing 154\n",
      "Processing 155\n",
      "Processing 156\n",
      "Processing 157\n",
      "Processing 158\n",
      "Processing 159\n",
      "Processing 160\n",
      "Processing 161\n",
      "Processing 162\n",
      "Processing 163\n",
      "Processing 164\n",
      "Processing 165\n",
      "Processing 166\n",
      "Processing 167\n",
      "Processing 168\n",
      "Processing 169\n",
      "Processing 170\n",
      "Processing 171\n",
      "Processing 172\n",
      "Processing 173\n",
      "Processing 174\n",
      "Processing 175\n",
      "Processing 176\n",
      "Processing 177\n",
      "Processing 178\n",
      "Processing 179\n",
      "Processing 180\n",
      "Processing 181\n",
      "Processing 182\n",
      "Processing 183\n",
      "Processing 184\n",
      "Processing 185\n",
      "Processing 186\n",
      "Processing 187\n",
      "Processing 188\n",
      "Processing 189\n",
      "Processing 190\n",
      "Processing 191\n",
      "Processing 192\n",
      "Processing 193\n",
      "Processing 194\n",
      "Processing 195\n",
      "Processing 196\n",
      "Processing 197\n",
      "Processing 198\n",
      "Processing 199\n",
      "Wrote submission to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# File: run_queries.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Configuration\n",
    "DB_PATH        = \"./chroma_db_task2\"\n",
    "QUERIES_CSV    = \"queries.csv\"\n",
    "SUBMISSION_CSV = \"submission.csv\"\n",
    "MODEL_ID       = \"microsoft/Phi-4-multimodal-instruct\"\n",
    "EMBEDDINGS     = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# 1. Load persisted Chroma vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
    "vectordb   = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)\n",
    "retriever  = vectordb.as_retriever(search_kwargs={\"k\": 20})\n",
    "\n",
    "# 2. Load tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID, trust_remote_code=True, use_fast=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, trust_remote_code=True,\n",
    "    device_map=\"cuda\", torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "# 3. Build a HF text-generation pipeline\n",
    "hf_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "# 4. Wrapper class to inject input_mode=0 while preserving .task\n",
    "class PipelineWithInputMode:\n",
    "    def __init__(self, pipe, input_mode=0):\n",
    "        self.pipeline = pipe\n",
    "        self.task = pipe.task  # ensure .task exists\n",
    "        self.input_mode = input_mode\n",
    "\n",
    "    def __call__(self, texts, **kwargs):\n",
    "        # 每次调用都加上 input_mode 参数\n",
    "        return self.pipeline(texts, input_mode=self.input_mode, **kwargs)\n",
    "\n",
    "# 5. Create LangChain LLM with wrapped pipeline\n",
    "wrapped = PipelineWithInputMode(hf_pipe, input_mode=0)\n",
    "llm = HuggingFacePipeline(pipeline=wrapped)\n",
    "\n",
    "# 6. Build RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 7. Read queries CSV and answer\n",
    "df      = pd.read_csv(QUERIES_CSV)\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    qid      = row['ID']\n",
    "    question = row['Question']\n",
    "    print(f\"Processing {qid}\")\n",
    "    output   = qa({\"query\": question})\n",
    "    docs     = output[\"source_documents\"]\n",
    "    page     = docs[0].metadata.get(\"page\") if docs else None\n",
    "    results.append({\"ID\": qid, \"Answer\": page})\n",
    "\n",
    "# 8. Save submission.csv\n",
    "pd.DataFrame(results).to_csv(SUBMISSION_CSV, index=False, encoding='utf-8-sig')\n",
    "print(f\"Wrote submission to {SUBMISSION_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INPUT ===\n",
      "On which page can you find information about the approach where reasoning involves answer inference conditioned on a rationale, contrasting it with direct prediction methods, and noting a performance drop exceeding 12%?\n",
      "\n",
      "=== ALL SOURCE DOCUMENTS ===\n",
      "\n",
      "--- Source Document #1 ---\n",
      "Page metadata: 223\n",
      "Content snippet:\n",
      "Page 223 Title: Multimodal CoT Reasoning  Summary: The slide discusses the impact of rationales on answer prediction in multimodal CoT reasoning. It provides an example where the No-CoT method predict ...\n",
      "\n",
      "\n",
      "--- Source Document #2 ---\n",
      "Page metadata: 193\n",
      "Content snippet:\n",
      "Page 193 Title: This Lecture – Agenda  Summary: The lecture agenda covers the basics of reasoning, including Chain-of-Thought (CoT) with zero-shot and few-shot reasoners, Analogical Reasoning, Multimo ...\n",
      "\n",
      "\n",
      "--- Source Document #3 ---\n",
      "Page metadata: 212\n",
      "Content snippet:\n",
      "Page 212 Title: This Lecture – Agenda  Summary: The lecture agenda includes topics on reasoning basics, chain-of-thought, zero-shot and few-shot reasoners, analogical reasoning, multimodal reasoning,  ...\n",
      "\n",
      "\n",
      "--- Source Document #4 ---\n",
      "Page metadata: 233\n",
      "Content snippet:\n",
      "Page 233 Title: This Lecture – Agenda  Summary: The lecture agenda includes topics on reasoning basics, chain-of-thought, zero-shot and few-shot reasoners, analogical reasoning, multimodal reasoning,  ...\n",
      "\n",
      "\n",
      "--- Source Document #5 ---\n",
      "Page metadata: 284\n",
      "Content snippet:\n",
      "Page 284 Title: Various reasoning benchmarks are emerging  Summary: The slide presents various reasoning benchmarks emerging in the field of Artificial Intelligence, specifically focusing on Hallucina ...\n",
      "\n",
      "\n",
      "--- Source Document #6 ---\n",
      "Page metadata: 280\n",
      "Content snippet:\n",
      "Page 280 Title: Various reasoning benchmarks are emerging  Summary: The slide presents various reasoning benchmarks, specifically MMBench [ECCV 2024], focusing on relation reasoning. It includes examp ...\n",
      "\n",
      "\n",
      "--- Source Document #7 ---\n",
      "Page metadata: 276\n",
      "Content snippet:\n",
      "Page 276 Title: Various reasoning benchmarks are emerging  Summary: The slide discusses the emergence of various reasoning benchmarks in the field of Artificial Intelligence, specifically mentioning t ...\n",
      "\n",
      "\n",
      "--- Source Document #8 ---\n",
      "Page metadata: 183\n",
      "Content snippet:\n",
      "Page 183 Title: This Lecture – Agenda  Summary: The lecture agenda includes topics on reasoning basics, chain-of-thought, zero-shot and few-shot reasoners, analogical reasoning, multimodal reasoning,  ...\n",
      "\n",
      "\n",
      "--- Source Document #9 ---\n",
      "Page metadata: 184\n",
      "Content snippet:\n",
      "Page 184 Title: This Lecture – Agenda  Summary: The lecture agenda includes topics on reasoning basics, chain-of-thought, zero-shot and few-shot reasoners, analogical reasoning, multimodal reasoning,  ...\n",
      "\n",
      "\n",
      "--- Source Document #10 ---\n",
      "Page metadata: 274\n",
      "Content snippet:\n",
      "Page 274 Title: This Lecture – Agenda  Summary: The lecture agenda includes topics on reasoning basics, chain-of-thought, zero-shot and few-shot reasoners, analogical reasoning, multimodal reasoning,  ...\n",
      "\n",
      "\n",
      "--- Source Document #11 ---\n",
      "Page metadata: 200\n",
      "Content snippet:\n",
      "Page 200 Title: Overview of Different Reasoning Methods  Summary: The slide provides an overview of different reasoning methods in AI, including generic guidance reasoning, 0-shot CoT, and analogical  ...\n",
      "\n",
      "\n",
      "--- Source Document #12 ---\n",
      "Page metadata: 283\n",
      "Content snippet:\n",
      "Page 283 Title: Various reasoning benchmarks are emerging  Summary: The slide presents various reasoning benchmarks, including MathVista, with examples of math problems and their solutions. It also co ...\n",
      "\n",
      "\n",
      "--- Source Document #13 ---\n",
      "Page metadata: 282\n",
      "Content snippet:\n",
      "Page 282 Title: Various reasoning benchmarks are emerging  Summary: The slide discusses emerging reasoning benchmarks, specifically MMVet at ICML 2024. It includes examples of mathematical problems an ...\n",
      "\n",
      "\n",
      "--- Source Document #14 ---\n",
      "Page metadata: 187\n",
      "Content snippet:\n",
      "Page 187 Title: What is reasoning?  Summary: The slide discusses the concept of reasoning, highlighting that humans can learn from a few examples due to their ability to reason. It suggests that AI sh ...\n",
      "\n",
      "\n",
      "--- Source Document #15 ---\n",
      "Page metadata: 278\n",
      "Content snippet:\n",
      "Page 278 Title: Various reasoning benchmarks are emerging  Summary: The slide discusses emerging reasoning benchmarks, specifically MMBench [ECCV 2024], which focuses on fine-grained perception (cross ...\n",
      "\n",
      "\n",
      "--- Source Document #16 ---\n",
      "Page metadata: 281\n",
      "Content snippet:\n",
      "Page 281 Title: Various reasoning benchmarks are emerging  Summary: The slide presents the emerging reasoning benchmarks in the field of Artificial Intelligence, specifically the MMBench presented at  ...\n",
      "\n",
      "\n",
      "--- Source Document #17 ---\n",
      "Page metadata: 277\n",
      "Content snippet:\n",
      "Page 277 Title: Various reasoning benchmarks are emerging  Summary: The slide discusses emerging reasoning benchmarks, specifically MMBench and Fine-grained Perception, and includes examples of object ...\n",
      "\n",
      "\n",
      "--- Source Document #18 ---\n",
      "Page metadata: 275\n",
      "Content snippet:\n",
      "Page 275 Title: Various reasoning benchmarks are emerging  Summary: The slide presents various reasoning benchmarks emerging in the field of artificial intelligence, specifically focusing on the MMS m ...\n",
      "\n",
      "\n",
      "--- Source Document #19 ---\n",
      "Page metadata: 175\n",
      "Content snippet:\n",
      "Page 175 Title: Artificial Intelligence  Summary: The slide is about Artificial Intelligence, specifically focusing on the concept of Reasoning. It is presented by Wen-Huang Cheng from National Taiwan ...\n",
      "\n",
      "\n",
      "--- Source Document #20 ---\n",
      "Page metadata: 205\n",
      "Content snippet:\n",
      "Page 205 Title: Inference Approaches  Summary: The slide presents three inference approaches in AI: Best-of-N search, Sentence-level Beam Search, and Stage-level Beam Search. Each approach is explaine ...\n",
      "\n",
      "=== OUTPUT ===\n",
      " Page 223\n"
     ]
    }
   ],
   "source": [
    "# 假設已經有 output = qa({\"query\": question})\n",
    "docs = output[\"source_documents\"]\n",
    "\n",
    "print(\"=== INPUT ===\")\n",
    "print(question)\n",
    "\n",
    "print(\"\\n=== ALL SOURCE DOCUMENTS ===\")\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\n--- Source Document #{i} ---\")\n",
    "    print(\"Page metadata:\", doc.metadata.get(\"page\"))\n",
    "    print(\"Content snippet:\")\n",
    "    print(doc.page_content[:200].replace(\"\\n\", \" \"), \"...\\n\")\n",
    "\n",
    "print(\"=== OUTPUT ===\")\n",
    "print(output[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
