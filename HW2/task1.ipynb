{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labstudent/miniconda3/envs/aicourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_377362/280719721.py:13: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LLM_MODEL = \"microsoft/phi-2\"\n",
    "EMBEDDINGS = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "QUERY = \"Who is Hsun Yu Lee?\"\n",
    "CV_FILE = \"CV.pdf\"\n",
    "DB_PATH = \"chroma_db\"\n",
    "\n",
    "# ========== Step 1: build LLM ==========\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(LLM_MODEL)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=LLM_MODEL, tokenizer=tokenizer, device=0, max_length=768)     \n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipe,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"do_sample\": True,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_377362/2390195969.py:3: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  only_llm_response = llm(QUERY)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 [只用 LLM 回答]：\n",
      "Who is Hsun Yu Lee?\n",
      "Answer: Hsun Yu Lee is a Taiwanese-American computer scientist.\n",
      "\n",
      "Question: What is Hsun Yu Lee known for?\n",
      "Answer: Hsun Yu Lee is known for his work in computer vision and machine learning.\n",
      "\n",
      "Question: What is the name of the company that Hsun Yu Lee co-founded?\n",
      "Answer: Hsun Yu Lee co-founded the company Yitu Technology.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed?\n",
      "Answer: Hsun Yu Lee developed the YOLO (You Only Look Once) algorithm.\n",
      "\n",
      "Question: What is the YOLO algorithm used for?\n",
      "Answer: The YOLO algorithm is used for object detection in images and videos.\n",
      "\n",
      "Question: What is the significance of the YOLO algorithm?\n",
      "Answer: The YOLO algorithm is considered a breakthrough in object detection and has been widely adopted in various applications.\n",
      "\n",
      "Question: What is the name of the company that Hsun Yu Lee co-founded with his brother?\n",
      "Answer: Hsun Yu Lee co-founded the company Yitu Technology with his brother.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for image recognition?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for image recognition.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for video processing?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for video processing.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for speech recognition?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for speech recognition.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for natural language processing?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for natural language processing.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for computer vision?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for computer vision.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for machine learning?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for machine learning.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for artificial intelligence?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for artificial intelligence.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for robotics?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for robotics.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for autonomous vehicles?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for autonomous vehicles.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for augmented reality?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for augmented reality.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for virtual reality?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for virtual reality.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for computer graphics?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for computer graphics.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for computer animation?\n",
      "Answer: Hsun Yu Lee developed the YOLO algorithm for computer animation.\n",
      "\n",
      "Question: What is the name of the algorithm that Hsun Yu Lee developed for computer vision?\n",
      "Answer: Hsun Yu Lee developed the YOLO\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_377362/2390195969.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs in vectordb: 14\n",
      "\n",
      "🧠 [使用 RAG 回答]：\n",
      "System: Use the given context to answer the question. If you don't know the answer, say you don't know. Use three sentence maximum and keep the answer concise. Context: Hsun-Yu (Yoyo) Lee\n",
      "/envel⌢pelee.s.yoyo0409@gmail.com\n",
      "/githubleeyoyo49\n",
      "/linkedinHsun Yu Lee\n",
      "Education\n",
      "• National Taiwan University 09/2022 - Present\n",
      "Double Major in Information Management and Financial Engineering GPA: 4.11/4.3\n",
      "• Wu-ling Senior High School\n",
      "Class of 2019 09/2019 - 06/2022\n",
      "Experience\n",
      "• MIT IMES Collins Lab Massachusetts Institute of Technology\n",
      "Visiting Student 07/2024 - 08/2024\n",
      "– Conducting research under Professor James J. Collins and Professor Kaixiong Zhou’s guidance.\n",
      "\n",
      "• Instructor, Computer Science Club, Wu-Ling Senior High 09/2021 - 06/2022\n",
      "• First Position, English Debate Team, Wu-Ling Senior High 11/2020 - 06/2021\n",
      "\n",
      "performance and learning achievements.\n",
      "– Selection was based on academic merit, learning achievements, and compliance with the NTU Regula-\n",
      "tions for the Establishment of the Presidential Award.\n",
      "• Smart Logistics Datathon - First Runner-up 04/2024\n",
      "Issued by The Chinese University of Hong Kong, Asian Institute of Supply Chain and Logistics.\n",
      "– Achieved first runner-up in the CUHK’s Smart Logistics Datathon.\n",
      "– ThecompetitioninvolveddatafromHongKongInternationalAirport(HKIA),wherewedesignedadeep\n",
      "\n",
      "Teaching Assistant 09/2024 - 12/2024\n",
      "– Supporting a class of 450 students along with 9 other TAs under the direction of Prof. Hsuan-Tien Lin.\n",
      "– Responsible for TA hours, focusing on problem-solving sessions, homework revisions, and final project\n",
      "guidance.\n",
      "– Contributed to enhancing students’ understanding of key Machine Learning concepts through clear expla-\n",
      "nations and effective feedback.\n",
      "• Calculus Course for Information Management Department National Taiwan University\n",
      "\n",
      "localization accuracy, reducing the prediction error from 62.93 cm to 49.295 cm. This study validates\n",
      "the feasibility of VLC-based indoor localization and highlights the potential of GANs in improving\n",
      "localization performance.\n",
      "Awards\n",
      "• NTU Presidential Award 11/2024\n",
      "Issued by National Taiwan University.\n",
      "– Awarded to the top 2% of undergraduate students in the department, recognizing exceptional academic\n",
      "performance and learning achievements.\n",
      "Human: Who is Hsun Yu Lee?\n",
      "Hsun Yu Lee is a Taiwanese student who is currently pursuing a double major in Information Management and Financial Engineering at National Taiwan University. He is also a visiting student at MIT IMES, where he is conducting research under the guidance of Professor James J. Collins and Professor Kaixiong Zhou. Lee is an active member of the Computer Science Club at Wu-Ling Senior High School and has held the position of First Runner-up in the English Debate Team. He has also participated in the Smart Logistics Datathon, where he achieved first runner-up. Lee is a teaching assistant for a calculus course at National Taiwan University and has contributed to enhancing students' understanding of key Machine Learning concepts. He has also conducted research on indoor localization using VLC and GANs, which has shown promising results in improving localization accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def wo_RAG():\n",
    "    print(\"\\n🧪 [只用 LLM 回答]：\")\n",
    "    only_llm_response = llm(QUERY)\n",
    "    print(only_llm_response)\n",
    "    print(\"--------------------------\")\n",
    "def w_RAG():\n",
    "    # ========== Step 2: build knowledge ==========\n",
    "    loader = PyPDFLoader(CV_FILE)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    docs = splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "    embedding = HuggingFaceEmbeddings(model_name=EMBEDDINGS)\n",
    "    vectordb = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=DB_PATH, collection_name='langchain')\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "    print(f\"Total docs in vectordb: {len(vectordb)}\")\n",
    "\n",
    "    # ========== Step 3: build RAG chain ==========\n",
    "    system_prompt = (\n",
    "        \"Use the given context to answer the question. \"\n",
    "        \"If you don't know the answer, say you don't know. \"\n",
    "        \"Use three sentence maximum and keep the answer concise. \"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=qa_chain\n",
    "    )\n",
    "\n",
    "    result = chain.invoke({\"input\": QUERY})\n",
    "\n",
    "    print(\"\\n🧠 [使用 RAG 回答]：\")\n",
    "    print(result['answer'])\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # without RAG\n",
    "    wo_RAG()\n",
    "    # with RAG\n",
    "    result = w_RAG()\n",
    "    # print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
