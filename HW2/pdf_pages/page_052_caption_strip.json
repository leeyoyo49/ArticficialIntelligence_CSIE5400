{
  "title": "Observations",
  "definitions": {
    "Open-web datasets": "Datasets used to train open text-to-image models",
    "LAION dataset": "A dataset used to train vision-language models",
    "Alt HTML tags (Alttext)": "A type of HTML tag used to provide alternative text for images",
    "Vision-language models": "Models that understand and generate visual content based on textual input",
    "Image generation": "The process of creating images from textual descriptions"
  },
  "formulas": [],
  "keywords": [
    "Open-web datasets",
    "LAION dataset",
    "Alt HTML tags (Alttext)",
    "Vision-language models",
    "Image generation"
  ],
  "summary": "The slide discusses the issues with open-web datasets used to train open text-to-image models, specifically the LAION dataset. It highlights that the captions in the LAION dataset, which come from alt HTML tags, often describe only a narrow aspect of the image, neglecting significant visual details. For example, an image of a person can have as Alttext the name of the person and the name of the photographer, but not a description of their appearance, their clothes, their position, or the background."
}