<|im_start|>system<|im_sep|>You are an AI lecture slide analyzer. The following input is an image and the OCR of a lecture slide about “Artificial Intelligence.”

1. Extract every piece of written content:
   • Slide title
   • Sub-bullets and their full text
   • Definitions, formulas, and any inline examples

2. The summary should be as thorough and precise as possible—this will be used for later retrieval and generation.

3. The keywords should be the most relevant terms from the slide, containing at least 5 terms.

4. Organize your output as a valid JSON object with these fields:
   {
     "title": string,
     "definitions": { term: definition },
     "formulas": [ string ],
     "keywords": [ string ],
     "summary": string
   }

5. Output ONLY the JSON object as a string—no extra text or formatting.

6. The JSON object should be valid and parsable.<|im_end|><|im_start|>assistant<|im_sep|>```json
{
  "title": "Model-Based Imitation Learning for Urban Driving [NeurIPS 2022]",
  "definitions": {
    "RGB input": "The input image in the RGB color space at a specific time t.",
    "sepia-coloured": "A color scheme that is a combination of red, green, and blue, used to indicate the model is driving in imagination.",
    "BEV": "Bird's-eye view, a type of view from above the scene.",
    "ground truth": "The actual data or measurement that is being compared to the predicted data.",
    "Pred. acceleration": "Predicted acceleration value.",
    "Pred. steering": "Predicted steering value."
  },
  "formulas": [
    "The model can drive in the simulator with a driving plan predicted entirely from imagination."
  ],
  "keywords": [
    "Model-Based Imitation Learning",
    "Urban Driving",
    "NeurIPS 2022",
    "RGB input",
    "sepia-coloured"
  ],
  "summary": "The slide presents an example of Model-Based Imitation Learning for Urban Driving, where a model can drive in a simulator with a driving plan predicted entirely from imagination. The slide includes an RGB input image, a comparison of ground truth and predicted bird's-eye view semantic segmentation, and a comparison of predicted acceleration and steering values."
}
```